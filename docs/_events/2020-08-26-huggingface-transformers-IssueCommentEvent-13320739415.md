---
event_type: IssueCommentEvent
avatar: "https://avatars.githubusercontent.com/u/14880223?"
user: abisee
date: 2020-08-26
repo_name: huggingface/transformers
html_url: https://github.com/huggingface/transformers/issues/4969
repo_url: https://github.com/huggingface/transformers
---

<a href='https://github.com/abisee' target='_blank'>abisee</a> commented on issue <a href='https://github.com/huggingface/transformers/issues/4969' target='_blank'>huggingface/transformers#4969</a>.

<small>> Applying the distillation to gpt2-xl the way we did for distilgpt2 (same ratios) would still result in a model that is bigger than gpt2-medium (24L, 1600 hidden dim). Would that fit your use-case?...</small>

<a href='https://github.com/huggingface/transformers/issues/4969' target='_blank'>View Comment</a>