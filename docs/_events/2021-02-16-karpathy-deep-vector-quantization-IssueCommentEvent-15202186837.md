---
event_type: IssueCommentEvent
avatar: "https://avatars.githubusercontent.com/u/241138?"
user: karpathy
date: 2021-02-16
repo_name: karpathy/deep-vector-quantization
html_url: https://github.com/karpathy/deep-vector-quantization/issues/1
repo_url: https://github.com/karpathy/deep-vector-quantization
---

<a href='https://github.com/karpathy' target='_blank'>karpathy</a> commented on issue <a href='https://github.com/karpathy/deep-vector-quantization/issues/1' target='_blank'>karpathy/deep-vector-quantization#1</a>.

<small>The einsum is basically just a matrix multiply but it is applied channelwise. It's basically a conv1x1 layer with bias=False, but I left it this way because it makes the embedding weights explicit in the module, which I kind of like, and this makes it also symmetric with what's happening on the vqvae side....</small>

<a href='https://github.com/karpathy/deep-vector-quantization/issues/1' target='_blank'>View Comment</a>